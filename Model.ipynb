{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca6359e-15fe-4914-9b73-36071dd03e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-30 18:19:23.174863: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import os\n",
    "from tensorflow.keras import Input, Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv3D, MaxPooling3D, BatchNormalization, Dropout, concatenate, Flatten, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from pathlib import Path\n",
    "from DataGenerator import DataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9517b34-ed1d-4d28-a0b8-57c7822f7ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "#keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7da2e6d5-bae0-4bfd-8611-dfa63788169f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "alz = pd.read_csv(\"alzheimers.csv\").drop_duplicates()\n",
    "conv = pd.read_csv(\"converted.csv\").drop_duplicates()\n",
    "non = pd.read_csv(\"nonconverted.csv\").drop_duplicates()\n",
    "cont = pd.read_csv(\"control.csv\").drop_duplicates()\n",
    "\n",
    "for index, row in alz.iterrows():\n",
    "    if not Path(\"petregistered/\" + str(row[\"PET_ID\"]) + \"_registered.nii.gz\").exists():\n",
    "        alz = alz.drop(index)\n",
    "\n",
    "\n",
    "for index, row in cont.iterrows():\n",
    "    if not Path(\"petregistered/\" + str(row[\"PET_ID\"]) + \"_registered.nii.gz\").exists():\n",
    "        cont = cont.drop(index)\n",
    "        \n",
    "for index, row in alz.iterrows():\n",
    "    if not Path(\"registered/\" + str(row[\"MRI_ID\"]) + \"_registered.nii.gz\").exists():\n",
    "        alz = alz.drop(index)\n",
    "\n",
    "\n",
    "for index, row in cont.iterrows():\n",
    "    if not Path(\"registered/\" + str(row[\"MRI_ID\"]) + \"_registered.nii.gz\").exists():\n",
    "        cont = cont.drop(index)        \n",
    "        \n",
    "posmarker = np.ones(len(alz))\n",
    "negmarker = np.zeros(len(cont))\n",
    "\n",
    "alz[\"marker\"] = posmarker\n",
    "cont[\"marker\"] = negmarker\n",
    "subjects = alz.append(cont)\n",
    "ids = subjects[[\"PET_ID\", \"MRI_ID\"]]\n",
    "markers = subjects[\"marker\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad27312e-68e5-4219-b68b-13789d7233cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "fold_no = 1\n",
    "petinput = Input(shape = (182, 218, 182, 1))\n",
    "mriinput = Input(shape = (182, 218, 182, 1))\n",
    "x = Conv3D(16, kernel_size = 3, activation = \"relu\", kernel_initializer='he_uniform', input_shape = (182, 218, 182, 1))(petinput)\n",
    "x = MaxPooling3D(pool_size = (2,2,2))(x)\n",
    "x = BatchNormalization(center=True, scale=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform')(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "x = BatchNormalization(center=True, scale=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Model(inputs = petinput, outputs = x)\n",
    "\n",
    "y = Conv3D(16, kernel_size = 3, activation = \"relu\", kernel_initializer='he_uniform', input_shape = (182, 218, 182, 1))(mriinput)\n",
    "y = MaxPooling3D(pool_size = (2,2,2))(y)\n",
    "y = BatchNormalization(center=True, scale=True)(y)\n",
    "y = Dropout(0.2)(y)\n",
    "y = Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform')(y)\n",
    "y = MaxPooling3D(pool_size=(2, 2, 2))(y)\n",
    "y = BatchNormalization(center=True, scale=True)(y)\n",
    "y = Dropout(0.2)(y)\n",
    "y = Model(inputs = mriinput, outputs = y)\n",
    "\n",
    "end = concatenate([x.output, y.output])\n",
    "z = Flatten()(end)\n",
    "z = Dense(10, kernel_initializer='he_uniform')(z)\n",
    "z = LeakyReLU()(z)\n",
    "z = Dense(8, kernel_initializer='he_uniform')(z)\n",
    "z = LeakyReLU()(z)\n",
    "z = Dense(5, kernel_initializer='he_uniform')(z)\n",
    "z = LeakyReLU()(z)\n",
    "z = Dense(1, activation = \"sigmoid\", kernel_initializer='he_uniform')(z)\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"mae\", \"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "872f4f4c-373a-45ed-9116-839776e35c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "111/111 [==============================] - 3268s 29s/step - loss: 249.7599 - mae: 0.5144 - acc: 0.4865 - val_loss: 758.1491 - val_mae: 0.6607 - val_acc: 0.3393\n",
      "Epoch 2/5\n",
      "111/111 [==============================] - 3255s 29s/step - loss: 119.1526 - mae: 0.2928 - acc: 0.7072 - val_loss: 128.1865 - val_mae: 0.6607 - val_acc: 0.3393\n",
      "Epoch 3/5\n",
      "111/111 [==============================] - 3262s 29s/step - loss: 55.4169 - mae: 0.1712 - acc: 0.8288 - val_loss: 203.3060 - val_mae: 0.3393 - val_acc: 0.6607\n",
      "Epoch 4/5\n",
      "111/111 [==============================] - 3251s 29s/step - loss: 31.8014 - mae: 0.1261 - acc: 0.8739 - val_loss: 174.0164 - val_mae: 0.3393 - val_acc: 0.6607\n",
      "Epoch 5/5\n",
      "111/111 [==============================] - 3260s 29s/step - loss: 10.4512 - mae: 0.0732 - acc: 0.9279 - val_loss: 86.8993 - val_mae: 0.2857 - val_acc: 0.7143\n",
      "Score for fold 1: loss of 86.89924621582031; mae of 28.57142984867096%\n",
      "Epoch 1/5\n",
      "111/111 [==============================] - 3266s 29s/step - loss: 45.3168 - mae: 0.1847 - acc: 0.8153 - val_loss: 183.9677 - val_mae: 0.4821 - val_acc: 0.5179\n",
      "Epoch 2/5\n",
      "111/111 [==============================] - 3267s 29s/step - loss: 24.2099 - mae: 0.1036 - acc: 0.8964 - val_loss: 3.5685 - val_mae: 0.0722 - val_acc: 0.9286\n",
      "Epoch 3/5\n",
      "111/111 [==============================] - 3257s 29s/step - loss: 10.4791 - mae: 0.0811 - acc: 0.9189 - val_loss: 301.2110 - val_mae: 0.5714 - val_acc: 0.4286\n",
      "Epoch 4/5\n",
      "111/111 [==============================] - 3255s 29s/step - loss: 16.0244 - mae: 0.0991 - acc: 0.9009 - val_loss: 38.3574 - val_mae: 0.3410 - val_acc: 0.6607\n",
      "Epoch 5/5\n",
      "111/111 [==============================] - 3257s 29s/step - loss: 15.5861 - mae: 0.0631 - acc: 0.9369 - val_loss: 149.3965 - val_mae: 0.5000 - val_acc: 0.5000\n",
      "Score for fold 2: loss of 149.39646911621094; mae of 50.00000596046448%\n",
      "Epoch 1/5\n",
      "111/111 [==============================] - 3263s 29s/step - loss: 18.3000 - mae: 0.0899 - acc: 0.9099 - val_loss: 49.6100 - val_mae: 0.3393 - val_acc: 0.6607\n",
      "Epoch 2/5\n",
      "111/111 [==============================] - 3252s 29s/step - loss: 23.4202 - mae: 0.0811 - acc: 0.9189 - val_loss: 176.7581 - val_mae: 0.4464 - val_acc: 0.5536\n",
      "Epoch 3/5\n",
      "111/111 [==============================] - 3260s 29s/step - loss: 10.3576 - mae: 0.0450 - acc: 0.9550 - val_loss: 18.8922 - val_mae: 0.2299 - val_acc: 0.7679\n",
      "Epoch 4/5\n",
      "111/111 [==============================] - 3248s 29s/step - loss: 5.2566 - mae: 0.0270 - acc: 0.9730 - val_loss: 160.8867 - val_mae: 0.4099 - val_acc: 0.5893\n",
      "Epoch 5/5\n",
      "111/111 [==============================] - 3250s 29s/step - loss: 3.4568 - mae: 0.0279 - acc: 0.9730 - val_loss: 33.9439 - val_mae: 0.3033 - val_acc: 0.6964\n",
      "Score for fold 3: loss of 33.943904876708984; mae of 30.327510833740234%\n",
      "Epoch 1/5\n",
      "111/111 [==============================] - 3262s 29s/step - loss: 7.4433 - mae: 0.0405 - acc: 0.9595 - val_loss: 343.7102 - val_mae: 0.4643 - val_acc: 0.5357\n",
      "Epoch 2/5\n",
      "111/111 [==============================] - 3261s 29s/step - loss: 2.7801 - mae: 0.0225 - acc: 0.9775 - val_loss: 59.6395 - val_mae: 0.3750 - val_acc: 0.6250\n",
      "Epoch 3/5\n",
      "111/111 [==============================] - 3261s 29s/step - loss: 14.3299 - mae: 0.0541 - acc: 0.9459 - val_loss: 0.2903 - val_mae: 0.0179 - val_acc: 0.9821\n",
      "Epoch 4/5\n",
      "111/111 [==============================] - 3250s 29s/step - loss: 3.3722 - mae: 0.0225 - acc: 0.9775 - val_loss: 4.3182 - val_mae: 0.0536 - val_acc: 0.9464\n",
      "Epoch 5/5\n",
      "111/111 [==============================] - 3254s 29s/step - loss: 35.6406 - mae: 0.1126 - acc: 0.8874 - val_loss: 329.0316 - val_mae: 0.4821 - val_acc: 0.5179\n",
      "Score for fold 4: loss of 329.03155517578125; mae of 48.21428656578064%\n",
      "Epoch 1/5\n",
      "112/112 [==============================] - 3291s 29s/step - loss: 32.1728 - mae: 0.1082 - acc: 0.8929 - val_loss: 325.4998 - val_mae: 0.4259 - val_acc: 0.5741\n",
      "Epoch 2/5\n",
      "112/112 [==============================] - 3285s 29s/step - loss: 2.9793 - mae: 0.0256 - acc: 0.9732 - val_loss: 33.9282 - val_mae: 0.1813 - val_acc: 0.8148\n",
      "Epoch 3/5\n",
      "112/112 [==============================] - 3298s 29s/step - loss: 5.6160 - mae: 0.0357 - acc: 0.9643 - val_loss: 17.5569 - val_mae: 0.1116 - val_acc: 0.8889\n",
      "Epoch 4/5\n",
      "112/112 [==============================] - 3288s 29s/step - loss: 1.5047e-24 - mae: 1.5047e-24 - acc: 1.0000 - val_loss: 7.7034 - val_mae: 0.0556 - val_acc: 0.9444\n",
      "Epoch 5/5\n",
      "112/112 [==============================] - 3288s 29s/step - loss: 1.7378 - mae: 0.0089 - acc: 0.9911 - val_loss: 104.3810 - val_mae: 0.3703 - val_acc: 0.6296\n",
      "Score for fold 5: loss of 109.89779663085938; mae of 37.03634738922119%\n"
     ]
    }
   ],
   "source": [
    "for train, test in kfold.split(ids, markers):\n",
    "# ids_train, ids_val, markers_train, markers_val = train_test_split(ids, markers, random_state = 42, stratify = markers, test_size = .25)\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((ids_train, markers_train)).map(grabfile)\n",
    "#val_dataset = tf.data.Dataset.from_tensor_slices((ids_val, markers_val))\n",
    "    checkpoint_filepath = 'temp/checkpoint'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        save_freq = \"epoch\",\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    batch_size = 2\n",
    "    train_generator = DataGenerator(ids.iloc[train], markers.iloc[train], batch_size = batch_size)\n",
    "    val_generator = DataGenerator(ids.iloc[test], markers.iloc[test], batch_size = batch_size)\n",
    "\n",
    "    history = model.fit(train_generator, validation_data = val_generator, callbacks=[model_checkpoint_callback], epochs = 5)\n",
    "    \n",
    "    scores = model.evaluate(val_generator, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c03d868b-6bcc-4a81-979c-2e2bcdff4c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3cf1863748>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd390e3e-e011-4e5e-9083-1566feaa66c1",
   "metadata": {},
   "source": [
    "mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd731893-4da6-4e4b-96a6-4d78e2f30bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in conv.iterrows():\n",
    "    if not Path(\"petregistered/\" + str(row[\"PET_ID\"]) + \"_registered.nii.gz\").exists():\n",
    "        conv = conv.drop(index)\n",
    "\n",
    "\n",
    "for index, row in non.iterrows():\n",
    "    if not Path(\"petregistered/\" + str(row[\"PET_ID\"]) + \"_registered.nii.gz\").exists():\n",
    "        non = non.drop(index)\n",
    "        \n",
    "for index, row in conv.iterrows():\n",
    "    if not Path(\"registered/\" + str(row[\"MRI_ID\"]) + \"_registered.nii.gz\").exists():\n",
    "        conv = conv.drop(index)\n",
    "\n",
    "\n",
    "for index, row in non.iterrows():\n",
    "    if not Path(\"registered/\" + str(row[\"MRI_ID\"]) + \"_registered.nii.gz\").exists():\n",
    "        non = non.drop(index)        \n",
    "        \n",
    "posmarker = np.ones(len(conv))\n",
    "negmarker = np.zeros(len(non))\n",
    "\n",
    "conv[\"marker\"] = posmarker\n",
    "non[\"marker\"] = negmarker\n",
    "subjects = conv.append(non)\n",
    "ids = subjects[[\"PET_ID\", \"MRI_ID\"]]\n",
    "markers = subjects[\"marker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ded6a51a-df0d-45ab-8199-d33d2ab8380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = keras.models.load_model(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59079201-7b43-4cf9-9d62-94d0b68a7ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 85s 3s/step - loss: 7.7034 - mean_absolute_error: 0.0556 - acc: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.703395366668701, 0.0555555559694767, 0.9444444179534912]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5d4b148-9628-4e1a-883a-b7e025fd959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 48s 3s/step - loss: 167.3555 - mae: 0.4375 - acc: 0.5625\n",
      "16/16 [==============================] - 49s 3s/step - loss: 129.7105 - mae: 0.4375 - acc: 0.5625\n",
      "16/16 [==============================] - 48s 3s/step - loss: 97.6654 - mae: 0.2977 - acc: 0.6875\n",
      "16/16 [==============================] - 48s 3s/step - loss: 33981.4141 - mae: 0.5312 - acc: 0.4688\n",
      "16/16 [==============================] - 48s 3s/step - loss: 154322.0469 - mae: 0.3125 - acc: 0.6875\n"
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "new.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"mae\", \"acc\"])\n",
    "\n",
    "for train, test in kfold.split(ids, markers):\n",
    "    new.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"mae\", \"acc\"])\n",
    "\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((ids_train, markers_train)).map(grabfile)\n",
    "#val_dataset = tf.data.Dataset.from_tensor_slices((ids_val, markers_val))\n",
    "    checkpoint_filepath = 'temp/checkpoint'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        save_freq = \"epoch\",\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    batch_size = 2\n",
    "    train_generator = DataGenerator(ids.iloc[train], markers.iloc[train], batch_size = batch_size)\n",
    "    val_generator = DataGenerator(ids.iloc[test], markers.iloc[test], batch_size = batch_size)\n",
    "\n",
    "    #model.fit(train_generator, validation_data = val_generator, callbacks=[model_checkpoint_callback], epochs = 5)\n",
    "    \n",
    "    scores = new.evaluate(val_generator)\n",
    "\n",
    "\n",
    "  # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ee950e6-37ba-4a2f-9ff3-19f79fd5b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in new.layers:\n",
    "    if type(layer) == Conv3D:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9e2a95a-e610-4ba6-97c3-79840fba8785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "64/64 [==============================] - 1875s 29s/step - loss: 9.6936 - mae: 0.0469 - acc: 0.9531 - val_loss: 9.1448 - val_mae: 0.2184 - val_acc: 0.7812\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 1861s 29s/step - loss: 5.2576 - mae: 0.0547 - acc: 0.9453 - val_loss: 22.5297 - val_mae: 0.2802 - val_acc: 0.7188\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 1861s 29s/step - loss: 6.8178 - mae: 0.0234 - acc: 0.9766 - val_loss: 59.9417 - val_mae: 0.3431 - val_acc: 0.6562\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 1863s 29s/step - loss: 1.7852 - mae: 0.0156 - acc: 0.9844 - val_loss: 29.6867 - val_mae: 0.4062 - val_acc: 0.5938\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 1879s 29s/step - loss: 1.4001 - mae: 0.0288 - acc: 0.9688 - val_loss: 10.3994 - val_mae: 0.1370 - val_acc: 0.8750\n",
      "Score for fold 1: loss of 110.10718536376953; mae of 40.625%\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 1877s 29s/step - loss: 7.7089e-04 - mae: 7.3408e-04 - acc: 1.0000 - val_loss: 2.5437 - val_mae: 0.0954 - val_acc: 0.9062\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 1874s 29s/step - loss: 4.1244 - mae: 0.0234 - acc: 0.9766 - val_loss: 0.8900 - val_mae: 0.0407 - val_acc: 0.9688\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 1864s 29s/step - loss: 0.6347 - mae: 0.0078 - acc: 0.9922 - val_loss: 13.0722 - val_mae: 0.2146 - val_acc: 0.7812\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 1862s 29s/step - loss: 4.0329 - mae: 0.0294 - acc: 0.9688 - val_loss: 22.4321 - val_mae: 0.2813 - val_acc: 0.7188\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 1863s 29s/step - loss: 1.2617 - mae: 0.0156 - acc: 0.9844 - val_loss: 0.6188 - val_mae: 0.0517 - val_acc: 0.9375\n",
      "Score for fold 2: loss of 70.00980377197266; mae of 28.12439203262329%\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 1875s 29s/step - loss: 1.9747e-17 - mae: 1.8046e-25 - acc: 1.0000 - val_loss: 0.2860 - val_mae: 0.0610 - val_acc: 0.9375\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 1861s 29s/step - loss: 2.6477e-05 - mae: 2.6431e-05 - acc: 1.0000 - val_loss: 0.3102 - val_mae: 0.0612 - val_acc: 0.9375\n",
      "Epoch 3/5\n",
      "35/64 [===============>..............] - ETA: 13:28 - loss: 3.6027e-13 - mae: 0.0000e+00 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2028/2875494178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mval_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"mae\", \"acc\"])\n",
    "\n",
    "for train, test in kfold.split(ids, markers):\n",
    "    model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"mae\", \"acc\"])\n",
    "\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((ids_train, markers_train)).map(grabfile)\n",
    "#val_dataset = tf.data.Dataset.from_tensor_slices((ids_val, markers_val))\n",
    "    checkpoint_filepath = 'temp/checkpoint'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        save_freq = \"epoch\",\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    batch_size = 2\n",
    "    train_generator = DataGenerator(ids.iloc[train], markers.iloc[train], batch_size = batch_size)\n",
    "    val_generator = DataGenerator(ids.iloc[test], markers.iloc[test], batch_size = batch_size)\n",
    "\n",
    "    new.fit(train_generator, validation_data = val_generator, callbacks=[model_checkpoint_callback], epochs = 5)\n",
    "    \n",
    "    scores = model.evaluate(val_generator, verbose = False)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "  # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76bd3032-deaa-495e-a147-11c715f94979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 49s 3s/step - loss: 36.5972 - mae: 0.3750 - acc: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[36.59720993041992, 0.37501227855682373, 0.625]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79366295-a2f7-448d-8cbf-b408e4d66d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: haha/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: haha/assets\n"
     ]
    }
   ],
   "source": [
    "new.save(\"haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520af57-7bce-4399-b6a1-72cb09b6fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(\"brains/322646.nii.gz\")\n",
    "img = img.get_fdata().squeeze()\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53154292-03c2-4268-a01f-34cdb22dc5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_slices(slices):\n",
    "    fig, axes = plt.subplots(1, len(slices))\n",
    "    for i, slice in enumerate(slices):\n",
    "        axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28b485-367c-43df-9884-5c632fc30ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_0 = img[90, :, :]\n",
    "slice_1 = img[:, 100, :]\n",
    "slice_2 = img[:, :, 160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64083387-8997-4379-a9a1-7da5289d58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices([slice_0, slice_1, slice_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df59ea-a01d-422e-b18d-4a37569d6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde916a-bbe4-4098-a073-3c1d00059365",
   "metadata": {},
   "outputs": [],
   "source": [
    "PET = patients.loc[(patients[\"Modality\"] == \"PET\")][\"Image ID\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae604e-a75e-4ab7-b816-b6b212a68fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv(\"idaSearch_7_07_2021 (3).csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b06e1a1-a5b1-467d-96bc-5a90be1c7b4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/696052098.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87c4688-2112-40ec-bff5-73836ac891cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1767/3696170357.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train_generator = DataGenerator(ids.iloc[train], markers.iloc[train], batch_size = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009be94-f0c6-4798-bf6f-10a0ec7eee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(train_generator.__getitem__(30)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a865d104-69f5-4792-9a76-e55b2735678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[1]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[1]\n",
      " [1]]\n",
      "[[1]\n",
      " [0]]\n",
      "[[1]\n",
      " [0]]\n",
      "[[1]\n",
      " [0]]\n",
      "[[1]\n",
      " [1]]\n",
      "[[0]\n",
      " [1]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[1]\n",
      " [0]]\n",
      "[[0]\n",
      " [1]]\n",
      "[[0]\n",
      " [0]]\n",
      "[[1]\n",
      " [1]]\n",
      "[[0]\n",
      " [1]]\n",
      "[[0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    print(train_generator.__getitem__(k)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9085c3-1249-48ac-9fd4-0dd0f1c91fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [0.]], shape=(2, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2028/2259661424.py\", line 2, in <module>\n",
      "    print(model(train_generator.__getitem__(k)[0]))\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 985, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\", line 386, in call\n",
      "    inputs, training=training, mask=mask)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\", line 508, in _run_internal_graph\n",
      "    outputs = node.layer(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 985, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/convolutional.py\", line 247, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1017, in convolution_v2\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1147, in convolution_internal\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 3005, in _conv3d_expanded_batch\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1406, in conv3d\n",
      "    padding, \"data_format\", data_format, \"dilations\", dilations)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2028/2259661424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 386\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1148\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv3d_expanded_batch\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   3004\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   3006\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv3d\u001b[0;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         padding, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1407\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    print(model(train_generator.__getitem__(k)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5c12844e-b7ec-4df0-9709-bc6772bab13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.layers[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2e949abd-4886-436f-97d4-191a31b32bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f925773ce80>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bd0b1-6da2-4a41-8b3a-e2ca979adc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9c9fa92a-cb89-4bd9-acdf-2b82b69414ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_7:0' shape=(None, 182, 218, 182, 1) dtype=float32>,\n",
       " <tf.Tensor 'input_8:0' shape=(None, 182, 218, 182, 1) dtype=float32>,\n",
       " <tf.Tensor 'conv3d_12/Relu:0' shape=(None, 180, 216, 180, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv3d_14/Relu:0' shape=(None, 180, 216, 180, 16) dtype=float32>,\n",
       " <tf.Tensor 'max_pooling3d_12/MaxPool3D:0' shape=(None, 90, 108, 90, 16) dtype=float32>,\n",
       " <tf.Tensor 'max_pooling3d_14/MaxPool3D:0' shape=(None, 90, 108, 90, 16) dtype=float32>,\n",
       " <tf.Tensor 'batch_normalization_12/batchnorm/add_1:0' shape=(None, 90, 108, 90, 16) dtype=float32>,\n",
       " <tf.Tensor 'batch_normalization_14/batchnorm/add_1:0' shape=(None, 90, 108, 90, 16) dtype=float32>,\n",
       " <tf.Tensor 'dropout_12/cond/Identity:0' shape=(None, 90, 108, 90, 16) dtype=float32>,\n",
       " <tf.Tensor 'dropout_14/cond/Identity:0' shape=(None, 90, 108, 90, 16) dtype=float32>,\n",
       " <tf.Tensor 'conv3d_13/Relu:0' shape=(None, 88, 106, 88, 32) dtype=float32>,\n",
       " <tf.Tensor 'conv3d_15/Relu:0' shape=(None, 88, 106, 88, 32) dtype=float32>,\n",
       " <tf.Tensor 'max_pooling3d_13/MaxPool3D:0' shape=(None, 44, 53, 44, 32) dtype=float32>,\n",
       " <tf.Tensor 'max_pooling3d_15/MaxPool3D:0' shape=(None, 44, 53, 44, 32) dtype=float32>,\n",
       " <tf.Tensor 'batch_normalization_13/batchnorm/add_1:0' shape=(None, 44, 53, 44, 32) dtype=float32>,\n",
       " <tf.Tensor 'batch_normalization_15/batchnorm/add_1:0' shape=(None, 44, 53, 44, 32) dtype=float32>,\n",
       " <tf.Tensor 'dropout_13/cond/Identity:0' shape=(None, 44, 53, 44, 32) dtype=float32>,\n",
       " <tf.Tensor 'dropout_15/cond/Identity:0' shape=(None, 44, 53, 44, 32) dtype=float32>,\n",
       " <tf.Tensor 'concatenate_3/concat:0' shape=(None, 44, 53, 44, 64) dtype=float32>,\n",
       " <tf.Tensor 'flatten_3/Reshape:0' shape=(None, 6566912) dtype=float32>,\n",
       " <tf.Tensor 'dense_12/Relu:0' shape=(None, 10) dtype=float32>,\n",
       " <tf.Tensor 'dense_13/Relu:0' shape=(None, 8) dtype=float32>,\n",
       " <tf.Tensor 'dense_14/Relu:0' shape=(None, 5) dtype=float32>,\n",
       " <tf.Tensor 'dense_15/Sigmoid:0' shape=(None, 1) dtype=float32>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3d06b15a-b608-4365-98c8-f0c1b8022767",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermed = Model(inputs = model.input, outputs = model.layers[22].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce3601-c9eb-4a59-8f80-91ec88863bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):    \n",
    "    intermed = Model(inputs = model.input, outputs = model.layers[18].output)\n",
    "    intermediate_output = intermed.predict(val_generator.__getitem__(20)[0])\n",
    "    print(intermediate_output, flush = True)\n",
    "    print(i, flush = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384272ad-8139-4b6c-b185-e5be3cfb6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d7b75-c452-49f7-9397-bb80be8f3c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
